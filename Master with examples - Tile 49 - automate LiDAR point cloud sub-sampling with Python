# How to automate LiDAR point cloud sub-sampling with Python
# Step 1 : Setting up the environment 
# Step 2: Load and prepare the data

pip install laspy

#libraries used
import numpy as np
import laspy as lp  # reads las pointcloud file 
import open3d as o3d # visualize file   


# Reference Code
# https://colab.research.google.com/drive/1addhGqN3ZE1mIn4L6jQnnkVs7_y__qSE?usp=sharing


#create paths and load data



#Load the file
dataname="Tile (49).las"
point_cloud = lp.read(dataname)


# examine the avaliable features for the lidar file we have reead
list(point_cloud.point_format.dimension_names)

set(list(point_cloud.classification))

# preperatin for visualization 
#Creating, filtering, and writing Point cloud data : Version 1
#store coordinates in "points", and colors in "colors" variable
points = np.vstack((point_cloud.x, point_cloud.y, point_cloud.z)).transpose()
colors = np.vstack((point_cloud.red, point_cloud.green, point_cloud.blue)).transpose()

#Creating, filtering, and writing Point cloud data : Version 2
# To create 3D point cloud data, we can stack together with the X, Y, Z dimensions using numpy

point_data = np.stack([point_cloud.X,point_cloud.Y,point_cloud.Z], axis = 0).transpose((1,0))


# 3D Point Cloud Visualization 
# Laspy has no visualizationm methods so that we wil use the open3d library, we first create
# the open34D geometries and pass the point data we have created. Finally we use the 
# open3D visualization to draw geometries. 

geom = o3d.geometry.PointCloud()
geom.points = o3d.utility.Vector3dVector(point_data)
o3d.visualization.draw_geometries([geom])

# 1 Point Cloud Decimation

#The decimation strategy, by setting a decimation factor
factor=160
decimated_points = points[::factor]
decimated_colors = colors[::factor]
len(decimated_points)

# 2 Point Cloud voxel grid

# Initialize the number of voxels to create to fill the space including every point
voxel_size=7
nb_vox=np.ceil((np.max(points, axis=0) - np.min(points, axis=0))/voxel_size)
#nb_vox.astype(int) #this gives you the number of voxels per axis

# Compute the non empty voxels and keep a trace of indexes that we can relate to points in order to store points later on.
# Also Sum and count the points in each voxel.
non_empty_voxel_keys, inverse, nb_pts_per_voxel= np.unique(((points - np.min(points, axis=0)) // voxel_size).astype(int), axis=0, return_inverse=True, return_counts=True)
idx_pts_vox_sorted=np.argsort(inverse)
#len(non_empty_voxel_keys) # if you need to display how many no-empty voxels you have

#Here, we loop over non_empty_voxel_keys numpy array to
#       > Store voxel indices as keys in a dictionnary
#       > Store the related points as the value of each key
#       > Compute each voxel barycenter and add it to a list
#       > Compute each voxel closest point to the barycenter and add it to a list

voxel_grid={}
grid_barycenter,grid_candidate_center=[],[]
last_seen=0

for idx,vox in enumerate(non_empty_voxel_keys):
  voxel_grid[tuple(vox)]=points[idx_pts_vox_sorted[last_seen:last_seen+nb_pts_per_voxel[idx]]]
  grid_barycenter.append(np.mean(voxel_grid[tuple(vox)],axis=0))
  grid_candidate_center.append(voxel_grid[tuple(vox)][np.linalg.norm(voxel_grid[tuple(vox)]-np.mean(voxel_grid[tuple(vox)],axis=0),axis=1).argmin()])
  last_seen+=nb_pts_per_voxel[idx]
  
  # Step 4: Vizualise and export the results
  
  import matplotlib.pyplot as plt
from mpl_toolkits import mplot3d
from matplotlib.pyplot import figure

figure(figsize=(12, 10), dpi=80)

ax = plt.axes(projection='3d')
ax.scatter(decimated_points[:,0], decimated_points[:,1], decimated_points[:,2], c = decimated_colors/65535, s=0.01)
plt.show()

#output_path = 
# %timeit np.savetxt(output_path+dataname+"_voxel-best_point_%s.xyz" % (voxel_size), grid_candidate_center, delimiter=";", fmt="%s")

# Load data
import open3d as o3d
import laspy as lp

dataname="Tile (49).las"
point_cloud =  lp.read(dataname)

pcd = o3d.geometry.PointCloud()
pcd.points = o3d.utility.Vector3dVector(points)
pcd.colors = o3d.utility.Vector3dVector(colors/65535)
# pcd.normals = o3d.utility.Vector3dVector(normals)
o3d.visualization.draw_geometries([pcd])

# Step 5 : Automate with functions

#Define a function that takes as input an array of points, and a voxel size expressed in meters. It returns the sampled point cloud
def grid_subsampling(points, voxel_size):

  nb_vox=np.ceil((np.max(points, axis=0) - np.min(points, axis=0))/voxel_size)
  non_empty_voxel_keys, inverse, nb_pts_per_voxel= np.unique(((points - np.min(points, axis=0)) // voxel_size).astype(int), axis=0, return_inverse=True, return_counts=True)
  idx_pts_vox_sorted=np.argsort(inverse)
  voxel_grid={}
  grid_barycenter,grid_candidate_center=[],[]
  last_seen=0

  for idx,vox in enumerate(non_empty_voxel_keys):
    voxel_grid[tuple(vox)]=points[idx_pts_vox_sorted[last_seen:last_seen+nb_pts_per_voxel[idx]]]
    grid_barycenter.append(np.mean(voxel_grid[tuple(vox)],axis=0))
    grid_candidate_center.append(voxel_grid[tuple(vox)][np.linalg.norm(voxel_grid[tuple(vox)]-np.mean(voxel_grid[tuple(vox)],axis=0),axis=1).argmin()])
    last_seen+=nb_pts_per_voxel[idx]

  return grid_candidate_center
  
  #Execute the function, and store the results in the grid_sampled_point_cloud variable
# grid_sampled_point_cloud = grid_subsampling(point_cloud, 6)

#Save the variable to an ASCII file to open in a 3D Software
# %timeit np.savetxt(output_path+dataname+"_sampled.xyz", grid_sampled_point_cloud variable, delimiter=";", fmt="%s")

import open3d as o3d
import numpy as np

def roty(t):
    """
    Rotation about the y-axis.
    """
    c = np.cos(t)
    s = np.sin(t)
    return np.array([[c, 0, s],
                     [0, 1, 0],
                     [-s, 0, c]])


def box_center_to_corner(box):
        
    translation = box[3:6]
    h, w, l = box[0], box[1], box[2]
    #if the angle value is in radian then use below mentioned conversion
    # rotation_y = box[6]
    # rotation = rotation_y * (180/math.pi)                             #rad to degree
    rotation = box[6]

    # Create a bounding box outline if x,y,z is center point then use defination bounding_box as mentioned below
    # bounding_box = np.array([
    #     [-l/2, -l/2, l/2, l/2, -l/2, -l/2, l/2, l/2],
    #     [w/2, -w/2, -w/2, w/2, w/2, -w/2, -w/2, w/2],
    #     [-h/2, -h/2, -h/2, -h/2, h/2, h/2, h/2, h/2]])
    
    # Create a bounding box outline if x,y,z is rear center point then use defination bounding_box as mentioned below
    bounding_box = np.array([
                [l,l,0,0,l,l,0,0],                      
                [w/2,-w/2,-w/2,w/2,w/2,-w/2,-w/2,w/2],          
                [0,0,0,0,h,h,h,h]])                        

    # Standard 3x3 rotation matrix around the Z axis
    rotation_matrix = np.array([
        [np.cos(rotation), -np.sin(rotation), 0.0],
        [np.sin(rotation), np.cos(rotation), 0.0],
        [0.0, 0.0, 1.0]])

    # Standard 3x3 rotation matrix around the X axis
    # rotation_matrix = np.array([
    #     [1.0, 0.0, 0.0],
    #     [0.0, np.sin(rotation), np.cos(rotation)],
    #     [0.0, 0.0, 1.0]])

    #rotation_matrix = roty(rotation)

    # Repeat the [x, y, z] eight times
    eight_points = np.tile(translation, (8, 1))


    # Translate the rotated bounding box by the
    # original center position to obtain the final box
    corner_box = np.dot(
        rotation_matrix, bounding_box) + eight_points.transpose()
    print(corner_box.transpose())

    return corner_box.transpose()


#box = [h,w,l,x,y,z,rot]
box = [1.7,2.1,5.1,7.5,-0.1,-0.1,0.02]

dataname="Tile (49).las"
point_cloud =  lp.read(dataname)

pcd1 = o3d.io.read_point_cloud('pointcloudfilename.pcd')
points_v = np.asarray(pcd.points)
mesh_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=2, origin=[0,0,0])
pcd = o3d.geometry.PointCloud()
pcd.points = o3d.utility.Vector3dVector(points)
entities_to_draw = [pcd, mesh_frame]

boxes3d_pts = box_center_to_corner(box)
boxes3d_pts = boxes3d_pts.T
boxes3d_pts = o3d.utility.Vector3dVector(boxes3d_pts.T)
box = o3d.geometry.OrientedBoundingBox.create_from_points(boxes3d_pts)
box.color = [1, 0, 0]           #Box color would be red box.color = [R,G,B]
entities_to_draw.append(box)

    # Draw
o3d.visualization.draw_geometries([*entities_to_draw],
                                         front=[-0.9945, 0.03873, 0.0970],
                                         lookat=[38.4120, 0.6139, 0.48500],
                                         up=[0.095457, -0.0421, 0.99453],
                                         zoom=0.33799
                                         )
 
 ########### EXAMPLE WITH OPEN3D TEST DATA #############
 # Load data
import open3d as o3 

print("Convert mesh to a point cloud and estimate dimensions")
armadillo = o3d.data.ArmadilloMesh()
mesh = o3d.io.read_triangle_mesh(armadillo.path)
mesh.compute_vertex_normals()

pcd = mesh.sample_points_poisson_disk(5000)
diameter = np.linalg.norm(
    np.asarray(pcd.get_max_bound()) - np.asarray(pcd.get_min_bound()))
o3d.visualization.draw_geometries([pcd])



#########################################

# Point Cloud Data Segmentation C++
# https://www.youtube.com/watch?v=17zf9e5ZK3I

#object detection lidar
#https://yagmurcigdemaktas.medium.com/object-detection-using-lidar-329ffd3deb16

############## RESOURCES ###############
# https://alteia.com/resources/blog/point-cloud-classification-and-machine-learning/
# https://paperswithcode.com/task/3d-point-cloud-classification
# https://info.vercator.com/blog/feature-extraction-from-point-cloud-data
# https://graphics.stanford.edu/courses/cs164-10-spring/Handouts/papers_gumhold.pdf
# https://github.com/agarret7/PointCNN/blob/master/core/model.py
# https://paperswithcode.com/paper/pointnet-deep-hierarchical-feature-learning#code
# https://developers.arcgis.com/python/guide/point-cloud-segmentation-using-pointcnn/
# https://towardsdatascience.com/a-gis-pipeline-for-lidar-point-cloud-feature-extraction-8cd1c686468a
# http://www.open3d.org/docs/latest/python_api/open3d.geometry.OrientedBoundingBox.html
# https://alteia.com/resources/blog/point-cloud-classification-and-machine-learning/
# https://github.com/hxdengBerkeley/PointCNN.Pytorch
# https://github.com/nicolas-chaulet/torch-points3d
# https://github.com/agarret7/PointCNN/blob/master/core/model.py
# http://jacoposerafin.com/wp-content/uploads/serafin16iros.pd
# https://learngeodata.eu/2021/05/14/learn-3d-point-cloud-segmentation-with-python/


############ YOUTUBE TUTORIALS ##############
# https://www.youtube.com/watch?v=vGr8Bg2Fda8&t=204s
# https://www.youtube.com/watch?v=_oFTKDwsbQ0&t=662s
# https://www.youtube.com/watch?v=6mivXP3rAfg&t=192s
# https://www.youtube.com/watch?v=GGxpqfTvE8c&t=2s
# https://www.youtube.com/watch?v=zF3MreN1w6c&list=PLkmvobsnE0GEZugH1Di2Cr_f32qYkv7aN
# https://www.youtube.com/watch?v=2bVdvgzYLeQ&t=226s
# https://www.youtube.com/watch?v=xFFCQVwYeec&t=2140s
# https://www.youtube.com/watch?v=zF3MreN1w6c&list=PLkmvobsnE0GEZugH1Di2Cr_f32qYkv7aN
# https://www.youtube.com/watch?v=29ZQ3TDGgRQ







  





  
  










